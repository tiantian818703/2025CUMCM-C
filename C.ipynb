{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfe3995",
   "metadata": {},
   "source": [
    "# NIPT的时点选择与胎儿的异常判定\n",
    "核心目标（来自题文约定）：\n",
    "\n",
    "1. 男胎：当 Y 染色体浓度 ≥ 4% 时认为“达标”，此时 NIPT 结果基本可靠；需尽量 早 达到达标\n",
    "   * 12周内 → 低风险\n",
    "   * 13–27周 → 高风险\n",
    "   * ≥28周 → 极高风险\n",
    "\n",
    "2. 女胎：无 Y 染色体，需判定 是否异常（以 21/18/13 号染色体“非整倍体 AB 列”为真值标签），综合利用 Z 值、GC 含量、读段数/比例、BMI 等信息构建判定方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b00dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from patsy import dmatrix\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "# 设置字体\n",
    "plt.rc('font', family= 'STIXGeneral', size= 12)  # 统一字体\n",
    "plt.rc('axes', titlesize= 12, labelsize= 10)\n",
    "plt.rc('legend', fontsize= 10)\n",
    "plt.rc('xtick', labelsize= 10)\n",
    "plt.rc('ytick', labelsize= 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d90089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 0. 工具 & 读取/清洗\n",
    "# ------------------------\n",
    "def parse_week_str(s):\n",
    "    \"\"\"把 '11w+6' 等形式解析为 11+6/7；其他数字直接转浮点。\"\"\"\n",
    "    if pd.isna(s): return np.nan\n",
    "    txt2 = re.sub(r'[^\\d\\+]', '', str(s))   # 只保留数字与'+'，如 '11w+6' -> '11+6'\n",
    "    m = re.search(r'(\\d+)\\+?(\\d*)', txt2)\n",
    "    if not m:\n",
    "        try: return float(txt2)\n",
    "        except: return np.nan\n",
    "    w = int(m.group(1))\n",
    "    d = int(m.group(2)) if m.group(2) != \"\" else 0\n",
    "    return w + d/7.0\n",
    "\n",
    "def find_col(df, keyword):\n",
    "    cands = [c for c in df.columns if keyword in str(c)]\n",
    "    return cands[0] if cands else None\n",
    "\n",
    "def load_and_clean(xlsx_path, outdir):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # 优先尝试只读取两个目标 sheet（如果存在），否则读取所有 sheet\n",
    "    try:\n",
    "        sheets = pd.read_excel(xlsx_path, sheet_name=[\"男胎检测数据\", \"女胎检测数据\"])\n",
    "        if isinstance(sheets, pd.DataFrame):\n",
    "            sheets = {\"Sheet1\": sheets}\n",
    "    except Exception:\n",
    "        sheets = pd.read_excel(xlsx_path, sheet_name=None)\n",
    "\n",
    "    # 规范化每个 sheet 的列名并补齐缺失列（保证各表列一致，女表缺列用 NaN 补全）\n",
    "    df_list = {}\n",
    "    for name, df in (sheets.items() if isinstance(sheets, dict) else []):\n",
    "        df = df.copy()\n",
    "        df.columns = [str(c).strip() for c in df.columns]\n",
    "        df_list[name] = df\n",
    "\n",
    "    if isinstance(df_list, dict) and len(df_list) > 1:\n",
    "        all_cols = set().union(*(set(df.columns) for df in df_list.values()))\n",
    "        for name, df in df_list.items():\n",
    "            for c in all_cols:\n",
    "                if c not in df.columns:\n",
    "                    df[c] = np.nan\n",
    "            df = df[[c for c in all_cols]]\n",
    "            df[\"_sheet\"] = name\n",
    "            df_list[name] = df\n",
    "        df = pd.concat(list(df_list.values()), ignore_index=True)\n",
    "    else:\n",
    "        if isinstance(sheets, dict):\n",
    "            df_all = []\n",
    "            for name, df0 in sheets.items():\n",
    "                df0 = df0.copy()\n",
    "                df0.columns = [str(c).strip() for c in df0.columns]\n",
    "                df0[\"_sheet\"] = name\n",
    "                df_all.append(df0)\n",
    "            df = pd.concat(df_all, ignore_index=True)\n",
    "        else:\n",
    "            df = sheets.copy()\n",
    "            df.columns = [str(c).strip() for c in df.columns]\n",
    "            df[\"_sheet\"] = \"Sheet1\"\n",
    "\n",
    "    # 尝试定位每个目标列（若列名略有不同则通过关键字匹配）\n",
    "    col_subject = find_col(df, \"孕妇代码\") or find_col(df, \"subject\") or find_col(df, \"id\")\n",
    "    col_week    = find_col(df, \"检测孕周\") or find_col(df, \"孕周\") or find_col(df, \"week\")\n",
    "    col_bmi     = find_col(df, \"孕妇BMI\") or find_col(df, \"BMI\")\n",
    "    col_age     = find_col(df, \"年龄\") or find_col(df, \"age\")\n",
    "    col_height  = find_col(df, \"身高\") or find_col(df, \"height\")\n",
    "    col_weight  = find_col(df, \"体重\") or find_col(df, \"weight\")\n",
    "    col_yconc   = find_col(df, \"Y染色体浓度\") or find_col(df, \"Y浓度\")\n",
    "    col_yz      = find_col(df, \"Y染色体的Z值\") or find_col(df, \"Y_Z\")\n",
    "    col_xz      = find_col(df, \"X染色体的Z值\") or find_col(df, \"X_Z\")\n",
    "    col_xconc   = find_col(df, \"X染色体浓度\") or find_col(df, \"X_conc\")\n",
    "    col_z13     = find_col(df, \"13号染色体的Z值\") or find_col(df, \"Z13\")\n",
    "    col_z18     = find_col(df, \"18号染色体的Z值\") or find_col(df, \"Z18\")\n",
    "    col_z21     = find_col(df, \"21号染色体的Z值\") or find_col(df, \"Z21\")\n",
    "    col_gc_all  = find_col(df, \"GC含量\") or find_col(df, \"GC_all\")\n",
    "    col_map     = find_col(df, \"在参考基因组上比对的比例\") or find_col(df, \"map_ratio\")\n",
    "    col_rep     = find_col(df, \"重复读段的比例\") or find_col(df, \"rep_ratio\")\n",
    "    col_reads_t = find_col(df, \"原始读段数\") or find_col(df, \"reads_total\")\n",
    "    col_reads_u = find_col(df, \"唯一比对的读段数\") or find_col(df, \"reads_unique\")\n",
    "    col_filt    = find_col(df, \"被过滤掉读段数的比例\") or find_col(df, \"filter_ratio\")\n",
    "    col_ab      = find_col(df, \"染色体的非整倍体\") or find_col(df, \"AB\")\n",
    "    col_health  = find_col(df, \"胎儿是否健康\") or find_col(df, \"health\")\n",
    "\n",
    "    # 使用用户提供的 dfp 构建方式，兼容缺失列\n",
    "    dfp = pd.DataFrame({\n",
    "        \"subject_id\": df[col_subject] if col_subject in df.columns else pd.Series(df.index, index=df.index),\n",
    "        \"gest_week\": df[col_week].apply(parse_week_str) if (col_week in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"BMI\": pd.to_numeric(df[col_bmi], errors=\"coerce\") if (col_bmi in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"age\": pd.to_numeric(df[col_age], errors=\"coerce\") if (col_age in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"height\": pd.to_numeric(df[col_height], errors=\"coerce\") if (col_height in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"weight\": pd.to_numeric(df[col_weight], errors=\"coerce\") if (col_weight in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"Y_conc\": pd.to_numeric(df[col_yconc], errors=\"coerce\") if (col_yconc in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"Y_Z\": pd.to_numeric(df[col_yz], errors=\"coerce\") if (col_yz in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"X_Z\": pd.to_numeric(df[col_xz], errors=\"coerce\") if (col_xz in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"X_conc\": pd.to_numeric(df[col_xconc], errors=\"coerce\") if (col_xconc in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"Z13\": pd.to_numeric(df[col_z13], errors=\"coerce\") if (col_z13 in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"Z18\": pd.to_numeric(df[col_z18], errors=\"coerce\") if (col_z18 in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"Z21\": pd.to_numeric(df[col_z21], errors=\"coerce\") if (col_z21 in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"GC_all\": pd.to_numeric(df[col_gc_all], errors=\"coerce\") if (col_gc_all in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"map_ratio\": pd.to_numeric(df[col_map], errors=\"coerce\") if (col_map in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"rep_ratio\": pd.to_numeric(df[col_rep], errors=\"coerce\") if (col_rep in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"reads_total\": pd.to_numeric(df[col_reads_t], errors=\"coerce\") if (col_reads_t in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"reads_unique\": pd.to_numeric(df[col_reads_u], errors=\"coerce\") if (col_reads_u in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"filter_ratio\": pd.to_numeric(df[col_filt], errors=\"coerce\") if (col_filt in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"AB\": df[col_ab].astype(str).str.strip() if (col_ab in df.columns) else pd.Series([\"\"]*len(df)),\n",
    "        \"health\": df[col_health] if (col_health in df.columns) else pd.Series([np.nan]*len(df)),\n",
    "        \"_sheet\": df[\"_sheet\"],\n",
    "    })\n",
    "\n",
    "    # 兼容老逻辑：保证 subject_id 为字符串，gest_week 已解析为数值\n",
    "    dfp[\"subject_id\"] = dfp[\"subject_id\"].astype(str)\n",
    "    if \"gest_week\" in dfp:\n",
    "        dfp[\"gest_week\"] = pd.to_numeric(dfp[\"gest_week\"], errors=\"coerce\")\n",
    "\n",
    "    # 性别：根据 sheet 判定\n",
    "    dfp[\"sex\"] = dfp[\"_sheet\"].apply(lambda x: \"male\" if \"男\" in str(x) else \"female\")\n",
    "\n",
    "    # 女胎异常标签（保留原 parse_ab 逻辑）\n",
    "    def parse_ab_local(x):\n",
    "        s = str(x).strip().lower()\n",
    "        if s in [\"\", \"nan\", \"none\", \"无异常\", \"正常\"]:\n",
    "            return 0\n",
    "        if \"异常\" in s or \"阳性\" in s:\n",
    "            return 1\n",
    "        return 0\n",
    "    dfp[\"abnormal\"] = dfp[\"AB\"].apply(parse_ab_local)\n",
    "\n",
    "    # 质量控制（与原逻辑相同）\n",
    "    dfp[\"QC_pass\"] = True\n",
    "    if \"GC_all\" in dfp: dfp.loc[~dfp[\"GC_all\"].between(0.40,0.60), \"QC_pass\"] = False\n",
    "    if \"map_ratio\" in dfp: dfp.loc[dfp[\"map_ratio\"]<0.60, \"QC_pass\"] = False\n",
    "    if \"filter_ratio\" in dfp: dfp.loc[dfp[\"filter_ratio\"]>0.60, \"QC_pass\"] = False\n",
    "\n",
    "    out_csv = os.path.join(outdir, \"cleaned_data.csv\")\n",
    "    dfp.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    return dfp\n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a0606",
   "metadata": {},
   "source": [
    "## 二、各子问题方案与结果\n",
    "\n",
    "### 问题1：男胎 Y 浓度与孕周、BMI 关系\n",
    "\n",
    "* **方法**：B 样条回归 + BMI 交互项\n",
    "* **结果**：`Q1_ols_summary.txt`（系数检验）与 `Q1_pred_curves.png`（曲线图）\n",
    "\n",
    "  * 不同 BMI 下的预测曲线\n",
    "  * 4% 横线标注达标时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba01608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 1. 问题1：Y~week+BMI（样条）\n",
    "# ------------------------\n",
    "def q1_model_and_plot(dfp, outdir, thr=0.04):\n",
    "    male = dfp[(dfp[\"sex\"]==\"male\") & dfp[\"gest_week\"].notna() & dfp[\"BMI\"].notna() & dfp[\"Y_conc\"].notna()].copy()\n",
    "    if len(male) < 30: return None\n",
    "    male[\"BMI_c\"] = male[\"BMI\"] - male[\"BMI\"].mean()\n",
    "    des = dmatrix(\"bs(gest_week, df=4, include_intercept=False)\", {\"gest_week\": male[\"gest_week\"]}, return_type='dataframe')\n",
    "    for i,c in enumerate(des.columns): male[f\"s{i+1}\"] = des[c].values\n",
    "    fml = \"Y_conc ~ s1+s2+s3+s4 + BMI_c + BMI_c:s1 + BMI_c:s2 + BMI_c:s3 + BMI_c:s4\"\n",
    "    fit = smf.ols(fml, data=male).fit(cov_type=\"HC3\")\n",
    "    with open(os.path.join(outdir, \"Q1_ols_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(fit.summary().as_text())\n",
    "    # 画预测曲线（%）\n",
    "    weeks = np.linspace(max(10.0, male[\"gest_week\"].min()), male[\"gest_week\"].max(), 200)\n",
    "    bmi_p = np.percentile(male[\"BMI\"], [10,50,90])\n",
    "    plt.figure()\n",
    "    for b in bmi_p:\n",
    "        dm = dmatrix(\"bs(w, df=4, include_intercept=False)\", {\"w\": weeks}, return_type='dataframe')\n",
    "        Xp = pd.DataFrame({\n",
    "            \"s1\": dm.iloc[:,0].values, \"s2\": dm.iloc[:,1].values, \"s3\": dm.iloc[:,2].values, \"s4\": dm.iloc[:,3].values,\n",
    "            \"BMI_c\": b - male[\"BMI\"].mean()\n",
    "        })\n",
    "        for k in [\"s1\",\"s2\",\"s3\",\"s4\"]:\n",
    "            Xp[f\"BMI_c:{k}\"] = Xp[\"BMI_c\"]*Xp[k]\n",
    "        yhat = fit.predict(Xp)*100.0\n",
    "        plt.plot(weeks, yhat, label=f\"BMI≈{b:.1f}\")\n",
    "    plt.axhline(4.0, linestyle=\"--\")\n",
    "    plt.xlabel(\"Gestational age (weeks)\")\n",
    "    plt.ylabel(\"Predicted Y concentration (%)\")\n",
    "    plt.title(\"Y concentration vs gestational age and BMI (spline regression)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(outdir, \"Q1_pred_curves.png\"), bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6acb92",
   "metadata": {},
   "source": [
    "### 问题2：BMI 分组与推荐时点\n",
    "\n",
    "* **步骤**：\n",
    "\n",
    "  1. 逐孕妇确定最早达标孕周\n",
    "  2. 回归树分组\n",
    "  3. 每组取 95% 分位作为推荐时点\n",
    "* **结果**：`Q2_BMI_bins_recommendations.csv`，包含：\n",
    "\n",
    "  * BMI 区间、人数、推荐时点\n",
    "  * 风险等级（低/高/极高）\n",
    "  * 阈值敏感性（3.5%、4.5%）\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbde470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 2. 问题2：BMI 分组 + 推荐时点（95%分位）+ 阈值敏感性\n",
    "# ------------------------\n",
    "def earliest_reach(group, thr=0.04):\n",
    "    g = group.sort_values(\"gest_week\")\n",
    "    conc = pd.to_numeric(g[\"Y_conc\"], errors=\"coerce\")\n",
    "    idx = np.where(conc >= thr)[0]\n",
    "    return g.iloc[idx[0]][\"gest_week\"] if len(idx)>0 else np.nan\n",
    "\n",
    "def q2_bmi_grouping(dfp, outdir, thr=0.04):\n",
    "    male = dfp[(dfp[\"sex\"]==\"male\") & dfp[\"gest_week\"].notna() & dfp[\"BMI\"].notna()].copy()\n",
    "    reach = male.groupby(\"subject_id\").apply(lambda g: earliest_reach(g, thr)).rename(\"earliest_week\").reset_index()\n",
    "    subj = male.drop_duplicates(\"subject_id\")[[\"subject_id\",\"BMI\"]].merge(reach, on=\"subject_id\", how=\"left\")\n",
    "    obs = subj.dropna(subset=[\"earliest_week\"]).copy()\n",
    "    if len(obs) < 30: return None\n",
    "    tree = DecisionTreeRegressor(max_leaf_nodes=5, min_samples_leaf=10, random_state=42).fit(obs[[\"BMI\"]].values, obs[\"earliest_week\"].values)\n",
    "    # 提取树阈值→BMI 分箱\n",
    "    t = tree.tree_; thresholds=[]\n",
    "    def walk(node):\n",
    "        if t.feature[node] != -2:\n",
    "            thresholds.append(t.threshold[node]); walk(t.children_left[node]); walk(t.children_right[node])\n",
    "    walk(0)\n",
    "    thr_sorted = sorted(set([x for x in thresholds if np.isfinite(x)]))\n",
    "    bmin, bmax = float(obs[\"BMI\"].min()), float(obs[\"BMI\"].max())\n",
    "    edges = [bmin-1e-6] + thr_sorted + [bmax+1e-6]\n",
    "    bins = pd.IntervalIndex.from_tuples(list(zip(edges[:-1], edges[1:])), closed=\"right\")\n",
    "    obs[\"bmi_bin\"] = pd.cut(obs[\"BMI\"], bins)\n",
    "    rows=[]\n",
    "    for iv in bins:\n",
    "        g = obs[obs[\"bmi_bin\"]==iv][\"earliest_week\"].dropna()\n",
    "        rec = float(np.percentile(g,95)) if len(g)>0 else np.nan\n",
    "        risk = \"低风险(≤12周)\" if rec<=12 else (\"高风险(13-27周)\" if rec<28 else \"极高风险(≥28周)\")\n",
    "        rows.append({\"BMI区间\": f\"({iv.left:.1f}, {iv.right:.1f}]\", \"人数\": int(len(g)), \"推荐时点(周)\": round(rec,2) if pd.notna(rec) else np.nan, \"风险等级\": risk})\n",
    "    tab = pd.DataFrame(rows)\n",
    "    # 阈值敏感性\n",
    "    def recs_for(th):\n",
    "        r2 = male.groupby(\"subject_id\").apply(lambda g: earliest_reach(g, th)).rename(\"earliest_week\")\n",
    "        s2 = male.drop_duplicates(\"subject_id\")[[\"subject_id\",\"BMI\"]].merge(r2, on=\"subject_id\", how=\"left\").dropna(subset=[\"earliest_week\"]).copy()\n",
    "        s2[\"bmi_bin\"] = pd.cut(s2[\"BMI\"], bins)\n",
    "        out=[]\n",
    "        for iv in bins:\n",
    "            g = s2[s2[\"bmi_bin\"]==iv][\"earliest_week\"].dropna()\n",
    "            out.append(float(np.percentile(g,95)) if len(g)>0 else np.nan)\n",
    "        return out\n",
    "    tab[\"阈值3.5%推荐(周)\"] = recs_for(0.035)\n",
    "    tab[\"阈值4.5%推荐(周)\"] = recs_for(0.045)\n",
    "    tab.to_csv(os.path.join(outdir, \"Q2_BMI_bins_recommendations.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a72cb",
   "metadata": {},
   "source": [
    "### 问题3：多因素逻辑回归与推荐时点\n",
    "\n",
    "* **模型**：带正则的逻辑回归（class\\_weight=balanced）\n",
    "* **评估**：5 折 AUC\n",
    "* **输出**：\n",
    "\n",
    "  * `Q3_multifactor_bins.csv`：BMI 分组与推荐时点\n",
    "  * `Q3_recommendation_CI.csv`：推荐时点的不确定区间（bootstrap）\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ae70623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 3. 问题3：多因素逻辑回归（正则） + BMI 依赖推荐时点 + bootstrap CI\n",
    "# ------------------------\n",
    "def q3_multifactor_logit(dfp, outdir, thr=0.04):\n",
    "    male = dfp[(dfp[\"sex\"]==\"male\") & dfp[\"gest_week\"].notna()].copy()\n",
    "    if len(male) < 80: return None\n",
    "    male[\"hit\"] = (pd.to_numeric(male[\"Y_conc\"], errors=\"coerce\") >= thr).astype(int)\n",
    "    des = dmatrix(\"bs(gest_week, df=4, include_intercept=False)\", {\"gest_week\": male[\"gest_week\"]}, return_type='dataframe').values\n",
    "    BMI_c = (male[\"BMI\"] - male[\"BMI\"].mean()).values.reshape(-1,1)\n",
    "    X = np.column_stack([des, BMI_c, des*BMI_c,\n",
    "                         (male[\"age\"]-male[\"age\"].mean()).values,\n",
    "                         (male[\"height\"]-male[\"height\"].mean()).values,\n",
    "                         (male[\"weight\"]-male[\"weight\"].mean()).values])\n",
    "    y = male[\"hit\"].values.astype(int)\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=4000, class_weight=\"balanced\", solver=\"liblinear\", C=1.0))\n",
    "    ])\n",
    "    # 5折 AUC\n",
    "    y_score_cv = cross_val_predict(pipe, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), method=\"predict_proba\")[:,1]\n",
    "    auc_cv = roc_auc_score(y, y_score_cv)\n",
    "    # 拟合全量并生成 BMI→推荐孕周\n",
    "    pipe.fit(X, y)\n",
    "    weeks = np.linspace(9.5, 30.0, 410)\n",
    "    dm = dmatrix(\"bs(w, df=4, include_intercept=False)\", {\"w\": weeks}, return_type='dataframe').values\n",
    "    def rec_week_for_bmi(bmi_val, p_target=0.95):\n",
    "        BMI_c0 = bmi_val - male[\"BMI\"].mean()\n",
    "        Xb = np.column_stack([dm, np.full((len(weeks),1), BMI_c0), dm*BMI_c0, np.zeros((len(weeks),3))])\n",
    "        p = pipe.predict_proba(Xb)[:,1]\n",
    "        idx = np.where(p>=p_target)[0]\n",
    "        return float(weeks[idx[0]]) if len(idx)>0 else np.nan\n",
    "    bmi_grid = np.linspace(np.nanpercentile(male[\"BMI\"],5), np.nanpercentile(male[\"BMI\"],95), 25)\n",
    "    recs = [rec_week_for_bmi(b) for b in bmi_grid]\n",
    "    q3_recs = pd.DataFrame({\"BMI\": np.round(bmi_grid,2), \"推荐时点P95(周)\": np.round(recs,2)})\n",
    "    # 以推荐时点的“阶跃变化”决定分组边界\n",
    "    edges=[float(q3_recs[\"BMI\"].min())]; last=None\n",
    "    for _,r in q3_recs.iterrows():\n",
    "        t=r[\"推荐时点P95(周)\"]; \n",
    "        if pd.isna(t): continue\n",
    "        if last is None: last=t; continue\n",
    "        if abs(t-last)>0.5: edges.append(float(r[\"BMI\"]))\n",
    "        last=t\n",
    "    edges.append(float(q3_recs[\"BMI\"].max()))\n",
    "    edges=sorted(set([round(e,1) for e in edges if np.isfinite(e)]))\n",
    "    bins = pd.IntervalIndex.from_tuples(list(zip(edges[:-1], edges[1:])), closed=\"right\")\n",
    "    q3_recs[\"bin\"]=pd.cut(q3_recs[\"BMI\"], bins)\n",
    "    group = q3_recs.groupby(\"bin\", observed=True)[\"推荐时点P95(周)\"].agg([\"count\",\"median\",\"min\",\"max\"]).reset_index()\n",
    "    group[\"BMI区间\"]=group[\"bin\"].apply(lambda iv:f\"({iv.left:.1f}, {iv.right:.1f}]\")\n",
    "    group[\"推荐时点(周)\"]=group[\"median\"].round(2)\n",
    "    group[[\"BMI区间\",\"count\",\"推荐时点(周)\",\"min\",\"max\"]].to_csv(os.path.join(outdir, \"Q3_multifactor_bins.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "    return auc_cv\n",
    "\n",
    "def q3_bootstrap_ci(dfp, outdir, thr=0.04, B=150):\n",
    "    # 计算 BMI 10/50/90 分位对应的推荐时点区间\n",
    "    male = dfp[(dfp[\"sex\"]==\"male\") & dfp[\"gest_week\"].notna()].copy()\n",
    "    if len(male) < 50: return None\n",
    "    male[\"hit\"] = (pd.to_numeric(male[\"Y_conc\"], errors=\"coerce\") >= thr).astype(int)\n",
    "    rng = np.random.default_rng(7)\n",
    "    def once(data, bmi_val, p_target=0.95):\n",
    "        from patsy import dmatrix\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        des = dmatrix(\"bs(gest_week, df=4, include_intercept=False)\", {\"gest_week\": data[\"gest_week\"]}, return_type='dataframe').values\n",
    "        BMI_c = (data[\"BMI\"] - data[\"BMI\"].mean()).values.reshape(-1,1)\n",
    "        X = np.column_stack([des, BMI_c, des*BMI_c,\n",
    "                             (data[\"age\"]-data[\"age\"].mean()).values,\n",
    "                             (data[\"height\"]-data[\"height\"].mean()).values,\n",
    "                             (data[\"weight\"]-data[\"weight\"].mean()).values])\n",
    "        y = data[\"hit\"].values.astype(int)\n",
    "        pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler()), (\"clf\", LogisticRegression(max_iter=4000, class_weight=\"balanced\", solver=\"liblinear\", C=1.0))])\n",
    "        try: pipe.fit(X, y)\n",
    "        except: return np.nan\n",
    "        weeks = np.linspace(9.5, 30.0, 410)\n",
    "        dm = dmatrix(\"bs(w, df=4, include_intercept=False)\", {\"w\": weeks}, return_type='dataframe').values\n",
    "        BMI_c0 = bmi_val - data[\"BMI\"].mean()\n",
    "        Xb = np.column_stack([dm, np.full((len(weeks),1), BMI_c0), dm*BMI_c0, np.zeros((len(weeks),3))])\n",
    "        p = pipe.predict_proba(Xb)[:,1]\n",
    "        idx = np.where(p>=p_target)[0]\n",
    "        return float(weeks[idx[0]]) if len(idx)>0 else np.nan\n",
    "    bmis = [np.nanpercentile(male[\"BMI\"], p) for p in [10,50,90]]\n",
    "    rows=[]\n",
    "    for b in bmis:\n",
    "        meds=[]\n",
    "        for _ in range(B):\n",
    "            idx = rng.choice(male.index.values, size=len(male), replace=True)\n",
    "            d = male.loc[idx]\n",
    "            val = once(d, b)\n",
    "            if pd.notna(val): meds.append(val)\n",
    "        if len(meds):\n",
    "            rows.append({\"BMI\": round(b,1), \"推荐时点中位数(周)\": round(float(np.median(meds)),2),\n",
    "                         \"2.5%\": round(float(np.percentile(meds,2.5)),2),\n",
    "                         \"97.5%\": round(float(np.percentile(meds,97.5)),2)})\n",
    "    if rows:\n",
    "        pd.DataFrame(rows).to_csv(os.path.join(outdir, \"Q3_recommendation_CI.csv\"), index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc841fdb",
   "metadata": {},
   "source": [
    "### 问题4：女胎异常判定\n",
    "\n",
    "* **透明规则**：\n",
    "\n",
    "  * 若 $\\max(Z_{13},Z_{18},Z_{21}) ≥ z_0$，判异常\n",
    "  * 最优阈值及对应 F1 输出到 `Q4_simple_rule.csv`\n",
    "* **逻辑回归融合模型**：\n",
    "\n",
    "  * 特征：Z 值 + GC 含量 + 读段质量 + BMI + 年龄\n",
    "  * 输出：`Q4_eval.csv`，包含 ROC-AUC、最佳阈值、混淆矩阵\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab8d5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# 4. 问题4：女胎异常判定（基线规则 + 逻辑回归）\n",
    "# ------------------------\n",
    "def q4_female_anomaly(dfp, outdir):\n",
    "    female = dfp[dfp[\"sex\"]==\"female\"].copy()\n",
    "\n",
    "    # ---- 改进标签识别 ----\n",
    "    def parse_ab(x):\n",
    "        s = str(x).strip().lower()\n",
    "        if s in [\"\", \"nan\", \"none\", \"无异常\", \"正常\"]:\n",
    "            return 0\n",
    "        if \"异常\" in s or \"阳性\" in s:\n",
    "            return 1\n",
    "        return 0\n",
    "    female[\"abnormal\"] = female[\"AB\"].apply(parse_ab)\n",
    "\n",
    "    # ---- 数据检查 ----\n",
    "    if len(female) < 20:\n",
    "        pd.DataFrame({\"note\": [f\"Female samples too few: {len(female)}\"]}) \\\n",
    "          .to_csv(os.path.join(outdir, \"Q4_note.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "        return None\n",
    "    if female[\"abnormal\"].nunique() < 2:\n",
    "        pd.DataFrame({\"note\": [\"No positive abnormal cases found in female samples\"]}) \\\n",
    "          .to_csv(os.path.join(outdir, \"Q4_note.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "        return None\n",
    "\n",
    "    # ---- 规则法 ----\n",
    "    y = female[\"abnormal\"].astype(int)\n",
    "    zmax = female[[\"Z13\",\"Z18\",\"Z21\"]].max(axis=1, skipna=True)\n",
    "    best_f1, best_z = -1.0, 3.0\n",
    "    for z0 in np.linspace(2.0, 5.0, 31):\n",
    "        f1 = f1_score(y, (zmax >= z0).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_z = f1, z0\n",
    "    pd.DataFrame({\n",
    "        \"Rule\": [\"If max(Z13,Z18,Z21) ≥ threshold → Abnormal\"],\n",
    "        \"Best_threshold\": [round(best_z, 2)],\n",
    "        \"F1_score(train)\": [round(best_f1, 3)]\n",
    "    }).to_csv(os.path.join(outdir, \"Q4_simple_rule.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # ---- 逻辑回归法 ----\n",
    "    X = female[[\"Z13\",\"Z18\",\"Z21\",\"X_Z\",\"X_conc\",\"GC_all\",\"reads_total\",\n",
    "                \"reads_unique\",\"map_ratio\",\"rep_ratio\",\"filter_ratio\",\n",
    "                \"BMI\",\"age\"]]\n",
    "    pipe = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "    ])\n",
    "    aucs = cross_val_score(pipe, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                           scoring=\"roc_auc\")\n",
    "    pipe.fit(X, y)\n",
    "    y_score = pipe.predict_proba(X)[:,1]\n",
    "    fpr, tpr, thr = roc_curve(y, y_score)\n",
    "    J = tpr - fpr\n",
    "    t_idx = np.argmax(J)\n",
    "    best_thr = thr[t_idx]\n",
    "    y_pred = (y_score >= best_thr).astype(int)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"metric\": [\"ROC-AUC(CV5-mean)\", \"Best_threshold\", \"TP\", \"FP\", \"FN\", \"TN\"],\n",
    "        \"value\": [round(float(np.mean(aucs)), 3),\n",
    "                  round(float(best_thr), 3),\n",
    "                  int(cm[1,1]), int(cm[0,1]), int(cm[1,0]), int(cm[0,0])]\n",
    "    }).to_csv(os.path.join(outdir, \"Q4_eval.csv\"), index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5816cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/j6829nfj6hz90xql1k5m7yh40000gn/T/ipykernel_49786/4207909544.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"_sheet\"] = name\n",
      "/var/folders/_h/j6829nfj6hz90xql1k5m7yh40000gn/T/ipykernel_49786/4207909544.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"_sheet\"] = name\n",
      "/opt/anaconda3/lib/python3.12/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 9, but rank is 8\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/var/folders/_h/j6829nfj6hz90xql1k5m7yh40000gn/T/ipykernel_49786/224720804.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  reach = male.groupby(\"subject_id\").apply(lambda g: earliest_reach(g, thr)).rename(\"earliest_week\").reset_index()\n",
      "/var/folders/_h/j6829nfj6hz90xql1k5m7yh40000gn/T/ipykernel_49786/224720804.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  r2 = male.groupby(\"subject_id\").apply(lambda g: earliest_reach(g, th)).rename(\"earliest_week\")\n",
      "/var/folders/_h/j6829nfj6hz90xql1k5m7yh40000gn/T/ipykernel_49786/224720804.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  r2 = male.groupby(\"subject_id\").apply(lambda g: earliest_reach(g, th)).rename(\"earliest_week\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done. Results in: nipt_outputs AUC(Q3)= 0.6282044676701137\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# main\n",
    "# ------------------------\n",
    "def main():\n",
    "    xlsx = \"附件.xlsx\"       # 放在同目录或给出绝对路径\n",
    "    outdir = \"nipt_outputs\"\n",
    "    dfp = load_and_clean(xlsx, outdir)\n",
    "    #dfp.to_csv(\"dfp_all_data.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    q1_model_and_plot(dfp, outdir, thr=0.04)\n",
    "    q2_bmi_grouping(dfp, outdir, thr=0.04)\n",
    "    auc_cv = q3_multifactor_logit(dfp, outdir, thr=0.04)\n",
    "    q3_bootstrap_ci(dfp, outdir, thr=0.04, B=150)\n",
    "    q4_female_anomaly(dfp, outdir)\n",
    "    print(\"All done. Results in:\", outdir, \"AUC(Q3)=\", auc_cv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee36cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
